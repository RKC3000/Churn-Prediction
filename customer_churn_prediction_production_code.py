# -*- coding: utf-8 -*-
"""Customer Churn Prediction_Production_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1txvjBvnmkYGIwmOjL9cRsIF7fnO1SvV6

Import all the required libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, roc_auc_score
import pickle

"""Load the data"""

try:
  data = pd.read_csv('data/Telco_Customer_Churn_lyst1769326950438.csv')
  print(f'\n Successfully loaded Customer Churn Data. Shape: {data.shape}')
except Exception as e:
  print(f'\n Error loading file: {e}')
  exit()

type(data)

"""Data Cleaning"""

data.info()

"""Clean TotalCharges"""

data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')

original_rows = len(data)

data = data.dropna(subset=['TotalCharges'])
print(f"Cleaned Total Charges: Dropped {original_rows - len(data)} rows with NaNs.")

data.columns

"""Dependent and Target Features"""

target_feature = 'Churn'
numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',
       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',
       'PaperlessBilling','PaymentMethod']

"""Combine all features for X and y"""

# X -> independent features
# y -> dependent features
X = data[numeric_features + categorical_features]
y = data[target_feature]

"""Target -> Churn

0 -> Not Churn

1 -> Churn
"""

# To find our churns and non churns are equal or not
from collections import Counter
Counter(y)

"""Split the data into train and test set"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=3, random_state=42, stratify=y)
# stratify parameter ensures that the class imbalance is represented in both the set [training and testing]

y_train = y_train.map({'Yes': 1, 'No': 0})
y_test = y_test.map({'Yes': 1, 'No': 0})
y = y.map({'Yes': 1, 'No': 0})

print(f"Original data churn rate: {y.mean():.4f}")
print(f"Training data churn rate: {y_train.mean():.4f}")
print(f"Testing data churn rate: {y_test.mean():.4f}")

"""**Full Stack Pipeline**"""

from sklearn.compose import ColumnTransformer

# --- 1. Numeric Preprocessing Batch
numeric_transformer  = Pipeline(steps = [
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# --- 2. Categorical Preprocessing Batch
categorical_transformer = Pipeline(steps = [
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# --- 3. Combine the above batches with ColumnTransformer
preprocessor = ColumnTransformer(
    transformers = [
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features),
    ],
    remainder = 'drop'
)

# --- 4. Create the final, full-stack pipeline
clf_pipeline = Pipeline(steps = [
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(
        class_weight = 'balanced',
        random_state = 42
    ))
])

"""Model Training on training set"""

clf_pipeline.fit(X_train, y_train)

"""Model Prediction"""

y_predict = clf_pipeline.predict(X_test)
print(y_predict)

y_prob = clf_pipeline.predict_proba(X_test)
print(y_prob)

# To find the probability of the Churn
y_prob = clf_pipeline.predict_proba(X_test)[:, 1]
print(y_prob)

"""Model Evaluation"""

print(confusion_matrix(y_test, y_predict))

print(recall_score(y_test, y_predict))



"""ROC-AUC Curve"""


"""Save the trained model using Pickle"""


with open('churn_prediction_model.pkl', 'wb') as file:
    pickle.dump(clf_pipeline, file)

print("âœ… Model saved successfully as 'churn_prediction_model.pkl'")


"""Load the model and predict on new data"""

# To load the model later for predictions, use:
#
# import pickle
# import pandas as pd
#
# with open('churn_prediction_model.pkl', 'rb') as file:
#     loaded_model = pickle.load(file)
#
# new_customer = pd.DataFrame({
#     'tenure': [12],
#     'MonthlyCharges': [65.0],
#     'TotalCharges': [780.0],
#     'gender': ['Male'],
#     'SeniorCitizen': [0],
#     'Partner': ['Yes'],
#     'Dependents': ['No'],
#     'PhoneService': ['Yes'],
#     'MultipleLines': ['No'],
#     'InternetService': ['Fiber optic'],
#     'OnlineSecurity': ['No'],
#     'OnlineBackup': ['Yes'],
#     'DeviceProtection': ['No'],
#     'TechSupport': ['No'],
#     'StreamingTV': ['Yes'],
#     'StreamingMovies': ['No'],
#     'Contract': ['Month-to-month'],
#     'PaperlessBilling': ['Yes'],
#     'PaymentMethod': ['Electronic check']
# })
#
# prediction = loaded_model.predict(new_customer)
# probability = loaded_model.predict_proba(new_customer)[:, 1]
# print(f"Churn Prediction: {'Yes' if prediction[0] == 1 else 'No'}")
# print(f"Churn Probability: {probability[0]:.2%}")
